{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1657f63",
   "metadata": {},
   "source": [
    "### EEGFormer for SEED dataset\n",
    "#### In this notebook I only demonstrate preprocessing + model forward.\n",
    "##### EEGFormer on raw SEED data (9_1.cnt): Considering computer memory limitations, only a part of the original data was selected for processing. The first 16 channels + first 300 seconds. (regarding the seed introduction file, 24s->264s: label=1ï¼› 289s->526s: label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e83fc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from math import gcd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import mne\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4f159c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: f:\\TUD\\Phd_application\\Oulu\\Code\n",
      "CNT: f:\\TUD\\Phd_application\\Oulu\\Code\\data\\seed_eeg\\9_1.cnt\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "root = None\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if (p / \"pretrained_weights\").exists() and (p / \"data\").exists():\n",
    "        root = p\n",
    "        break\n",
    "\n",
    "print(\"Project root:\", root)\n",
    "\n",
    "CNT_PATH = root / \"data\" / \"seed_eeg\" / \"9_1.cnt\"\n",
    "print(\"CNT:\", CNT_PATH)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c49def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream windows to avoid huge memory allocation\n",
    "def iter_seed_cnt_windows(\n",
    "    raw: mne.io.BaseRaw,\n",
    "    t_max_sec: float = 300.0,\n",
    "    win_sec: float = 4.0,\n",
    "    stride_sec: float = 1.0,\n",
    "    first_n_ch: int = 16,\n",
    "    target_fs: float | None = 250.0,\n",
    "    zscore_mode: str = \"per_window\",\n",
    "):\n",
    "\n",
    "    sfreq = float(raw.info[\"sfreq\"])\n",
    "    max_samp = int(t_max_sec * sfreq)\n",
    "    win_samp = int(round(win_sec * sfreq))\n",
    "    stride_samp = int(round(stride_sec * sfreq))\n",
    "\n",
    "    if target_fs is not None:\n",
    "        orig_fs_int = int(round(sfreq))\n",
    "        tgt_fs_int  = int(round(target_fs))\n",
    "        g = gcd(orig_fs_int, tgt_fs_int)\n",
    "        up = tgt_fs_int // g\n",
    "        down = orig_fs_int // g\n",
    "    else:\n",
    "        up = down = None\n",
    "\n",
    "    for s in range(0, max_samp - win_samp + 1, stride_samp):\n",
    "        seg = raw.get_data(start=s, stop=s + win_samp)\n",
    "        seg = seg[:first_n_ch].astype(np.float32)\n",
    "\n",
    "        if target_fs is not None:\n",
    "            seg = signal.resample_poly(seg, up=up, down=down, axis=1).astype(np.float32)\n",
    "\n",
    "        if zscore_mode == \"per_window\":\n",
    "            mean = seg.mean(axis=1, keepdims=True)\n",
    "            std  = seg.std(axis=1, keepdims=True) + 1e-8\n",
    "            seg = (seg - mean) / std\n",
    "        elif zscore_mode == \"none\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"zscore_mode must be 'per_window' or 'none'\")\n",
    "\n",
    "        yield s, seg.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b33dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Original sfreq: 1000.0\n",
      "Selected channels: 16\n",
      "ch_names: ['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yin Hang\\AppData\\Local\\Temp\\ipykernel_12736\\3676708471.py:9: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = mne.io.read_raw_cnt(str(CNT_PATH), preload=False, verbose=\"ERROR\")\n",
      "C:\\Users\\Yin Hang\\AppData\\Local\\Temp\\ipykernel_12736\\3676708471.py:9: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = mne.io.read_raw_cnt(str(CNT_PATH), preload=False, verbose=\"ERROR\")\n"
     ]
    }
   ],
   "source": [
    "T_MAX_SEC   = 300.0  # the first 300 seconds\n",
    "FIRST_N_CH  = 16     # the first 16 EEG channels\n",
    "WIN_SEC     = 4.0    # window length\n",
    "STRIDE_SEC  = 1.0    # stride\n",
    "\n",
    "TARGET_FS   = 250.0  # resample to 250 Hz to reduce compute\n",
    "ZSCORE_MODE = \"per_window\"\n",
    "\n",
    "raw = mne.io.read_raw_cnt(str(CNT_PATH), preload=False, verbose=\"ERROR\")\n",
    "picks = mne.pick_types(raw.info, eeg=True, eog=False, emg=False, stim=False, exclude=[])\n",
    "raw.pick(picks)\n",
    "\n",
    "raw.pick_channels(raw.ch_names[:FIRST_N_CH])\n",
    "\n",
    "sfreq = float(raw.info[\"sfreq\"])\n",
    "print(\"Original sfreq:\", sfreq)\n",
    "print(\"Selected channels:\", len(raw.ch_names))\n",
    "print(\"ch_names:\", raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89db0f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows_torch: torch.Size([297, 1000, 16]) (N, L, C)\n",
      "single sample: torch.Size([1000, 16]) (L, C)\n",
      "num windows: 297\n"
     ]
    }
   ],
   "source": [
    "all_w = []\n",
    "all_start_samples = []\n",
    "\n",
    "for s, w_lc in iter_seed_cnt_windows(\n",
    "    raw,\n",
    "    t_max_sec=T_MAX_SEC,\n",
    "    win_sec=WIN_SEC,\n",
    "    stride_sec=STRIDE_SEC,\n",
    "    first_n_ch=FIRST_N_CH,\n",
    "    target_fs=TARGET_FS,\n",
    "    zscore_mode=ZSCORE_MODE,\n",
    "):\n",
    "    all_start_samples.append(s)\n",
    "    all_w.append(w_lc)\n",
    "\n",
    "windows = np.stack(all_w, axis=0)\n",
    "windows_torch = torch.tensor(windows, dtype=torch.float32, device=device)\n",
    "\n",
    "print(\"windows_torch:\", windows_torch.shape, \"(N, L, C)\")\n",
    "print(\"single sample:\", windows_torch[0].shape, \"(L, C)\")\n",
    "print(\"num windows:\", len(all_start_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b44c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[0.6274, 0.3726]], device='cuda:0')\n",
      "predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "if str(root) not in sys.path:\n",
    "    sys.path.append(str(root))\n",
    "\n",
    "from EEGformer.models import EEGformer\n",
    "\n",
    "x0 = windows_torch[0]\n",
    "\n",
    "model = EEGformer(\n",
    "    input=x0,\n",
    "    num_cls=2,\n",
    "    input_channels=FIRST_N_CH,\n",
    "    kernel_size=10,\n",
    "    num_blocks=1,\n",
    "    num_heads_RTM=1,\n",
    "    num_heads_STM=1,\n",
    "    num_heads_TTM=1,\n",
    "    num_submatrices=1,\n",
    "    CF_second=2,\n",
    "    dtype=torch.float32\n",
    ").to(device)\n",
    "\n",
    "# Inference mode (no training here)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = model(x0)  # output probabilities\n",
    "\n",
    "print(\"y:\", y)\n",
    "print(\"predicted class:\", torch.argmax(y, dim=1).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhyeeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
